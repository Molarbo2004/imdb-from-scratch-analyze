### –¢–£–¢ –£ –ù–ê–° –°–†–ê–í–ù–ò–í–ê–Æ–¢–°–Ø –ú–û–î–ï–õ–ò: –°–õ–£–ß–ê–ù–´–ô –õ–ï–°, –†–ï–ì–†–ï–°–°–ò–Ø –ò –ù–ê–ò–í–ù–´–ô –ë–ê–ô–ï–°  ### 
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import re
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

df = pd.read_csv('data/imdb_reviews.csv', encoding='utf-8')


def preprocessor(text):
    if isinstance(text, float):  # –ó–∞—â–∏—Ç–∞ –æ—Ç NaN
        return ""
    # –£–¥–∞–ª—è–µ–º HTML-—Ç–µ–≥–∏
    text = re.sub(r'<[^>]*>', '', text)
    
    # –ò—â–µ–º —Å–º–∞–π–ª–∏–∫–∏ (—ç–º–æ—Ç–∏–∫–æ–Ω—ã) 
    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\)|\(|D|P)', text)
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ-–±—É–∫–≤–µ–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã 
    text = re.sub(r'[\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', '')
    
    return text.strip()


# –û—á–∏—â–∞–µ–º –≤—Å–µ –æ—Ç–∑—ã–≤—ã
print("–û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç...")
df['cleaned_review'] = df['review'].apply(preprocessor)


# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏

X_train, X_test, y_train, y_test = train_test_split(
    df['cleaned_review'], df['sentiment'], test_size=0.2, random_state=42
)


# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

vectorizer = TfidfVectorizer(
    max_features=5000,      # –±–µ—Ä–µ–º 5000 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
    ngram_range=(1, 3),     # —É—á–∏—Ç—ã–≤–∞–µ–º 1,2,3-–≥—Ä–∞–º–º—ã
    stop_words='english'    # —É–¥–∞–ª—è–µ–º —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã
)

X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)


models = {
    "LogisticRegression": LogisticRegression(),
    "NaiveBayes": MultinomialNB(),
    "RandomForest": RandomForestClassifier()
}

best_model = []
accuracy_massiv = []
best_model_name = ""
best_accuracy = 0
#1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
for key, value in models.items(): 
    value.fit(X_train_vec, y_train)
    y_pred = value.predict(X_test_vec)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å {key} –º–µ—Ç–æ–¥–∞: {accuracy}")
    accuracy_massiv.append(accuracy)
    if accuracy >= best_accuracy:
        best_accuracy = accuracy
        best_model_name = key

best_model.append(max(accuracy_massiv))
print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:", best_model_name, "–ï–µ —Ç–æ—á–Ω–æ—Å—Ç—å:", best_model[0])

# 2. ROC-–∫—Ä–∏–≤—ã–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä')

colors = ["darkorange", "green", "red"]  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏

for i, (key, model) in enumerate(models.items()): 
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
    y_pred_proba = model.predict_proba(X_test_vec)[:, 1]
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)
    
    # –†–∏—Å—É–µ–º –∫—Ä–∏–≤—É—é —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º —Ü–≤–µ—Ç–æ–º
    plt.plot(fpr, tpr, color=colors[i], lw=2, 
             label=f'{key} (AUC = {roc_auc:.2f})')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-–∫—Ä–∏–≤—ã–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.show()



# =============================================
# –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö: –õ–û–ñ–ù–û-–ü–û–ó–ò–¢–ò–í–ù–´–ï –ò –õ–û–ñ–ù–û-–ù–ï–ì–ê–¢–ò–í–ù–´–ï –û–¢–ó–´–í–´
# =============================================

print("\n" + "="*70)
print("üîç –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö –ú–û–î–ï–õ–ò")
print("="*70)


# –í–´–Ø–í–õ–ï–ù–ò–ï –û–®–ò–ë–û–ö

# 1. –õ–æ–∂–Ω–æ-–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ (–Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –ù–ï–ì–ê–¢–ò–í–ù–´–ï, –Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –ü–û–ó–ò–¢–ò–í–ù–´–ï)
false_positives = X_test[(y_test == 0) & (y_pred == 1)]
print(f"\n –õ–û–ñ–ù–û-–ü–û–ó–ò–¢–ò–í–ù–´–ï (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã, —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∫–∞–∫ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ): {len(false_positives)} —à—Ç.")
print("–ü—Ä–∏–º–µ—Ä—ã:")
for i, (_, text) in enumerate(false_positives[:3].items()):
    original_review = df.loc[df['cleaned_review'] == text, 'review'].iloc[0]  # –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç —Å HTML/–ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π
    print(f"  {i+1}. {original_review[:150]}...")

# 2. –õ–æ–∂–Ω–æ-–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ (–Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –ü–û–ó–ò–¢–ò–í–ù–´–ï, –Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –ù–ï–ì–ê–¢–ò–í–ù–´–ï)
false_negatives = X_test[(y_test == 1) & (y_pred == 0)]
print(f"\n –õ–û–ñ–ù–û-–ù–ï–ì–ê–¢–ò–í–ù–´–ï (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã, —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∫–∞–∫ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ): {len(false_negatives)} —à—Ç.")
print("–ü—Ä–∏–º–µ—Ä—ã:")
for i, (_, text) in enumerate(false_negatives[:3].items()):
    original_review = df.loc[df['cleaned_review'] == text, 'review'].iloc[0]
    print(f"  {i+1}. {original_review[:150]}...")

# 3. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –∏—â–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
print("\n" + "-"*70)
print(" –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
print("- –õ–æ–∂–Ω—ã–µ –ø–æ–∑–∏—Ç–∏–≤—ã —á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–∞—Ä–∫–∞–∑–º –∏–ª–∏ –∏—Ä–æ–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Oh great...').")
print("- –õ–æ–∂–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏, —Å –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ–π –ª–µ–∫—Å–∏–∫–æ–π –∏–ª–∏ –±–µ–∑ —è–≤–Ω—ã—Ö '–∫–ª—é—á–µ–≤—ã—Ö' —Å–ª–æ–≤.")
print("- –ú–æ–¥–µ–ª—å –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ–∑ n-–≥—Ä–∞–º–º.")
print("- –≠–º–æ–¥–∑–∏ –∏–Ω–æ–≥–¥–∞ —Å–ø–∞—Å–∞—é—Ç, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É—é—Ç –∏—Ä–æ–Ω–∏—é.")












